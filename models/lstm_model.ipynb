{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/valeriaalesnikova/Desktop/bootcamp/nlp_project-1/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/valeriaalesnikova/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('russian'))\n",
    "stemmer = SnowballStemmer('russian') \n",
    "sw = stopwords.words('russian')   \n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, embedding_dim: int, hidden_size:int, embedding: torch.nn.modules.sparse.Embedding) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = embedding\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.embedding_dim,\n",
    "            hidden_size=self.hidden_size,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.clf = nn.Linear(self.hidden_size, 6)  # Изменено для предсказания 6 классов\n",
    "\n",
    "    def forward(self, x):\n",
    "        embeddings = self.embedding(x)\n",
    "        _, (h_n, _) = self.lstm(embeddings)\n",
    "        out = self.clf(h_n.squeeze())\n",
    "        return out\n",
    "\n",
    "\n",
    "def data_preprocessing(text: str) -> str:\n",
    "    \"\"\"preprocessing string: lowercase, removing html-tags, punctuation, \n",
    "                            stopwords, digits\n",
    "\n",
    "    Args:\n",
    "        text (str): input string for preprocessing\n",
    "\n",
    "    Returns:\n",
    "        str: preprocessed string\n",
    "    \"\"\"    \n",
    "\n",
    "    text = text.lower()\n",
    "    text = re.sub('<.*?>', '', text) # html tags\n",
    "    text = ''.join([c for c in text if c not in string.punctuation])# Remove punctuation\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    text = [word for word in text.split() if not word.isdigit()]\n",
    "    text = ' '.join(text)\n",
    "    return text\n",
    "\n",
    "def get_words_by_freq(sorted_words: list, n: int = 10) -> list:\n",
    "    return list(filter(lambda x: x[1] > n, sorted_words))\n",
    "\n",
    "def padding(review_int: list, seq_len: int) -> np.array: # type: ignore\n",
    "    \"\"\"Make left-sided padding for input list of tokens\n",
    "\n",
    "    Args:\n",
    "        review_int (list): input list of tokens\n",
    "        seq_len (int): max length of sequence, it len(review_int[i]) > seq_len it will be trimmed, else it will be padded by zeros\n",
    "\n",
    "    Returns:\n",
    "        np.array: padded sequences\n",
    "    \"\"\"    \n",
    "    features = np.zeros((len(review_int), seq_len), dtype = int)\n",
    "    for i, review in enumerate(review_int):\n",
    "        if len(review) <= seq_len:\n",
    "            zeros = list(np.zeros(seq_len - len(review)))\n",
    "            new = zeros + review\n",
    "        else:\n",
    "            new = review[: seq_len]\n",
    "        features[i, :] = np.array(new)\n",
    "            \n",
    "    return features\n",
    "\n",
    "def preprocess_single_string(\n",
    "    input_string: str, \n",
    "    seq_len: int, \n",
    "    vocab_to_int: dict,\n",
    "    ) -> torch.tensor:\n",
    "    \"\"\"Function for all preprocessing steps on a single string\n",
    "\n",
    "    Args:\n",
    "        input_string (str): input single string for preprocessing\n",
    "        seq_len (int): max length of sequence, it len(review_int[i]) > seq_len it will be trimmed, else it will be padded by zeros\n",
    "        vocab_to_int (dict, optional): word corpus {'word' : int index}. Defaults to vocab_to_int.\n",
    "\n",
    "    Returns:\n",
    "        list: preprocessed string\n",
    "    \"\"\"    \n",
    "\n",
    "    preprocessed_string = data_preprocessing(input_string)\n",
    "    result_list = []\n",
    "    for word in preprocessed_string.split():\n",
    "        try: \n",
    "            result_list.append(vocab_to_int[word])\n",
    "        except KeyError as e:\n",
    "            print(f'{e}: not in dictionary!')\n",
    "    result_padded = padding([result_list], seq_len)[0]\n",
    "\n",
    "    return torch.tensor(result_padded)\n",
    "\n",
    "def predict_sentence(text: str, model: nn.Module, seq_len: int, vocab_to_int: dict) -> str:\n",
    "    rating_dict = {\n",
    "        0: \"Отвратительно! Даже не подходите к этому месту!\",\n",
    "        1: \"Плохо! Лучше бы остался дома.\",\n",
    "        2: \"Удовлетворительно, но не без недостатков. Ешьте на свой страх и риск.\",\n",
    "        3: \"Хорошо! Вполне достойное место для трапезы.\",\n",
    "        4: \"Отлично! Обязательно вернусь еще раз.\",\n",
    "        5: \"Великолепно! Как в раю, только с едой.\"\n",
    "    }\n",
    "    \n",
    "    p_str = preprocess_single_string(text, seq_len, vocab_to_int).unsqueeze(0)\n",
    "    model.eval()\n",
    "    pred = model(p_str)\n",
    "    output = pred.argmax(dim=1).item()\n",
    "    return rating_dict[output]\n",
    "\n",
    "def predict_single_string(text: str,\n",
    "                          model: BertModel,\n",
    "                          loaded_model: LogisticRegression\n",
    ") -> str:\n",
    "    rating_dict = {\n",
    "        0: \"Отвратительно! Даже не подходите к этому месту!\",\n",
    "        1: \"Плохо! Лучше бы остался дома.\",\n",
    "        2: \"Удовлетворительно, но не без недостатков. Ешьте на свой страх и риск.\",\n",
    "        3: \"Хорошо! Вполне достойное место для трапезы.\",\n",
    "        4: \"Отлично! Обязательно вернусь еще раз.\",\n",
    "        5: \"Великолепно! Как в раю, только с едой.\"\n",
    "    }\n",
    "\n",
    "    with torch.no_grad():\n",
    "        encoded_input = tokenizer(text, return_tensors='pt')\n",
    "        output = model(**encoded_input)\n",
    "        vector = output[0][:,0,:]\n",
    "        prediction = loaded_model.predict(vector)[0]\n",
    "    return rating_dict[prediction]\n",
    "\n",
    "def clean(text):\n",
    "\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\s+', ' ', text)  # заменить два и более пробела на один пробел\n",
    "    text = re.sub(r'\\d+', ' ', text) # удаляем числа\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation)) # удаляем знаки пунктуации \n",
    "    text = re.sub(r'\\n+', ' ', text) # удаляем символ перевод строки \n",
    "    \n",
    "    return text\n",
    "\n",
    "def tokin(text):\n",
    "    text = clean(text)\n",
    "    text = ' '.join([stemmer.stem(word) for word in text.split()])\n",
    "    text = ' '.join([word for word in text.split() if word not in sw])\n",
    "    return text\n",
    "\n",
    "def predict_ml_class(text, loaded_vectorizer, loaded_classifier):\n",
    "    rating_dict = {\n",
    "        0: \"Отвратительно! Даже не подходите к этому месту!\",\n",
    "        1: \"Плохо! Лучше бы остался дома.\",\n",
    "        2: \"Удовлетворительно, но не без недостатков. Ешьте на свой страх и риск.\",\n",
    "        3: \"Хорошо! Вполне достойное место для трапезы.\",\n",
    "        4: \"Отлично! Обязательно вернусь еще раз.\",\n",
    "        5: \"Великолепно! Как в раю, только с едой.\"\n",
    "    }\n",
    "    \n",
    "    t = tokin(text).split(' ')\n",
    "    new_text_bow = loaded_vectorizer.transform(t)\n",
    "    predicted_label = loaded_classifier.predict(new_text_bow)[0]\n",
    "    return rating_dict[predicted_label]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('russian'))\n",
    "import json\n",
    "from train_rnn import train_rnn_multiclass\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torchutils as tu\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import Adam\n",
    "from torchmetrics.classification import Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Лучше всего установить такую же версию\n",
    "# print(gensim.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка данных\n",
    "file_path = '/Users/valeriaalesnikova/Desktop/bootcamp/nlp_project-1/models/restaurants_reviews.jsonl'\n",
    "data = []\n",
    "with open(file_path, 'r') as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(text: str) -> str:\n",
    "    \"\"\"preprocessing string: lowercase, removing html-tags, punctuation and stopwords\n",
    "\n",
    "    Args:\n",
    "        text (str): input string for preprocessing\n",
    "\n",
    "    Returns:\n",
    "        str: preprocessed string\n",
    "    \"\"\"    \n",
    "\n",
    "    text = text.lower()\n",
    "    text = re.sub('<.*?>', '', text) # html tags\n",
    "    text = ''.join([c for c in text if c not in string.punctuation])# Remove punctuation\n",
    "    text = [word for word in text.split() if word not in stop_words] \n",
    "    text = ' '.join(text)\n",
    "    return text\n",
    "\n",
    "df['cleaned_text'] = df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>general</th>\n",
       "      <th>food</th>\n",
       "      <th>interior</th>\n",
       "      <th>service</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>Вытянули меня сегодня в город и раз уж была в ...</td>\n",
       "      <td>Вытянули меня сегодня в город и раз уж была в ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>проводили корпоратив на 60 чел. в этот - уже т...</td>\n",
       "      <td>проводили корпоратив на 60 чел. в этот - уже т...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>Был в Гостях с женой один раз и еще раз с жено...</td>\n",
       "      <td>Был в Гостях с женой один раз и еще раз с жено...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>Бар понравился на первый взгляд .  Интерьер к ...</td>\n",
       "      <td>Бар понравился на первый взгляд .  Интерьер к ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>В « Bel Canto » мы отмечали юбилей моего отца ...</td>\n",
       "      <td>В « Bel Canto » мы отмечали юбилей моего отца ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>Здравствуйте , уважаемые женихи и невесты .  Г...</td>\n",
       "      <td>Здравствуйте , уважаемые женихи и невесты .  Г...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>Вкусная кухня , уютная остановка , хорошее обс...</td>\n",
       "      <td>Вкусная кухня , уютная остановка , хорошее обс...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>Вкусная кухня , интересная обстановка , отличн...</td>\n",
       "      <td>Вкусная кухня , интересная обстановка , отличн...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>8 июня заказали 2 пиццы - Бергамо и Юнет .  Пи...</td>\n",
       "      <td>8 июня заказали 2 пиццы - Бергамо и Юнет .  Пи...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>Началась жаркая пора в нашем летнем расписании...</td>\n",
       "      <td>Началась жаркая пора в нашем летнем расписании...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>были 2 раза , заказывали с собой индийскую кух...</td>\n",
       "      <td>были 2 раза , заказывали с собой индийскую кух...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>были там 2-3 раза .. первый раз шашлык был тот...</td>\n",
       "      <td>были там 2-3 раза .. первый раз шашлык был тот...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>неплохо ! были раз 5-7 .. вкусно но не в восто...</td>\n",
       "      <td>неплохо ! были раз 5-7 .. вкусно но не в восто...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Была сегодня в районе Загородного и в районе о...</td>\n",
       "      <td>Была сегодня в районе Загородного и в районе о...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>Здравствуйте ! 29.05 посетили Фиш Хаус .  У на...</td>\n",
       "      <td>Здравствуйте ! 29.05 посетили Фиш Хаус .  У на...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    review_id  general food interior service  \\\n",
       "0           0        0   10       10      10   \n",
       "1           1        0    9       10       9   \n",
       "2           2        0    9       10      10   \n",
       "3           3        0    -        5      10   \n",
       "4           4        0    7       10      10   \n",
       "5           5        0   10       10      10   \n",
       "6           6        0   10       10      10   \n",
       "7           7        0   10       10      10   \n",
       "8           8        0    1        -       1   \n",
       "9           9        0    -        5       7   \n",
       "10         10        0    7        7       8   \n",
       "11         11        0    6        6       4   \n",
       "12         12        0    6        7       7   \n",
       "13         13        0    8        7       8   \n",
       "14         14        0   10       10      10   \n",
       "\n",
       "                                                 text  \\\n",
       "0   Вытянули меня сегодня в город и раз уж была в ...   \n",
       "1   проводили корпоратив на 60 чел. в этот - уже т...   \n",
       "2   Был в Гостях с женой один раз и еще раз с жено...   \n",
       "3   Бар понравился на первый взгляд .  Интерьер к ...   \n",
       "4   В « Bel Canto » мы отмечали юбилей моего отца ...   \n",
       "5   Здравствуйте , уважаемые женихи и невесты .  Г...   \n",
       "6   Вкусная кухня , уютная остановка , хорошее обс...   \n",
       "7   Вкусная кухня , интересная обстановка , отличн...   \n",
       "8   8 июня заказали 2 пиццы - Бергамо и Юнет .  Пи...   \n",
       "9   Началась жаркая пора в нашем летнем расписании...   \n",
       "10  были 2 раза , заказывали с собой индийскую кух...   \n",
       "11  были там 2-3 раза .. первый раз шашлык был тот...   \n",
       "12  неплохо ! были раз 5-7 .. вкусно но не в восто...   \n",
       "13  Была сегодня в районе Загородного и в районе о...   \n",
       "14  Здравствуйте ! 29.05 посетили Фиш Хаус .  У на...   \n",
       "\n",
       "                                         cleaned_text  \n",
       "0   Вытянули меня сегодня в город и раз уж была в ...  \n",
       "1   проводили корпоратив на 60 чел. в этот - уже т...  \n",
       "2   Был в Гостях с женой один раз и еще раз с жено...  \n",
       "3   Бар понравился на первый взгляд .  Интерьер к ...  \n",
       "4   В « Bel Canto » мы отмечали юбилей моего отца ...  \n",
       "5   Здравствуйте , уважаемые женихи и невесты .  Г...  \n",
       "6   Вкусная кухня , уютная остановка , хорошее обс...  \n",
       "7   Вкусная кухня , интересная обстановка , отличн...  \n",
       "8   8 июня заказали 2 пиццы - Бергамо и Юнет .  Пи...  \n",
       "9   Началась жаркая пора в нашем летнем расписании...  \n",
       "10  были 2 раза , заказывали с собой индийскую кух...  \n",
       "11  были там 2-3 раза .. первый раз шашлык был тот...  \n",
       "12  неплохо ! были раз 5-7 .. вкусно но не в восто...  \n",
       "13  Была сегодня в районе Загородного и в районе о...  \n",
       "14  Здравствуйте ! 29.05 посетили Фиш Хаус .  У на...  "
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [word for text in df['cleaned_text'] for word in text.split()]\n",
    "count_words = Counter(corpus)\n",
    "\n",
    "sorted_words = count_words.most_common()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words_by_freq(sorted_words: list, n: int = 10) -> list:\n",
    "    return list(filter(lambda x: x[1] > n, sorted_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_to_int = {w:i+1 for i, (w,c) in enumerate(sorted_words)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_int = []\n",
    "for text in df['cleaned_text']:\n",
    "\n",
    "    r = [vocab_to_int[word] for word in text.split() if vocab_to_int.get(word)]\n",
    "    reviews_int.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['general'] = df['general'].apply(lambda x: 1 if x == 'positive' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>general</th>\n",
       "      <th>food</th>\n",
       "      <th>interior</th>\n",
       "      <th>service</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>Review len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>Вытянули меня сегодня в город и раз уж была в ...</td>\n",
       "      <td>Вытянули меня сегодня в город и раз уж была в ...</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>проводили корпоратив на 60 чел. в этот - уже т...</td>\n",
       "      <td>проводили корпоратив на 60 чел. в этот - уже т...</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>Был в Гостях с женой один раз и еще раз с жено...</td>\n",
       "      <td>Был в Гостях с женой один раз и еще раз с жено...</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>Бар понравился на первый взгляд .  Интерьер к ...</td>\n",
       "      <td>Бар понравился на первый взгляд .  Интерьер к ...</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>В « Bel Canto » мы отмечали юбилей моего отца ...</td>\n",
       "      <td>В « Bel Canto » мы отмечали юбилей моего отца ...</td>\n",
       "      <td>354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_id  general food interior service  \\\n",
       "0          0        0   10       10      10   \n",
       "1          1        0    9       10       9   \n",
       "2          2        0    9       10      10   \n",
       "3          3        0    -        5      10   \n",
       "4          4        0    7       10      10   \n",
       "\n",
       "                                                text  \\\n",
       "0  Вытянули меня сегодня в город и раз уж была в ...   \n",
       "1  проводили корпоратив на 60 чел. в этот - уже т...   \n",
       "2  Был в Гостях с женой один раз и еще раз с жено...   \n",
       "3  Бар понравился на первый взгляд .  Интерьер к ...   \n",
       "4  В « Bel Canto » мы отмечали юбилей моего отца ...   \n",
       "\n",
       "                                        cleaned_text  Review len  \n",
       "0  Вытянули меня сегодня в город и раз уж была в ...         330  \n",
       "1  проводили корпоратив на 60 чел. в этот - уже т...         158  \n",
       "2  Был в Гостях с женой один раз и еще раз с жено...         103  \n",
       "3  Бар понравился на первый взгляд .  Интерьер к ...         157  \n",
       "4  В « Bel Canto » мы отмечали юбилей моего отца ...         354  "
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_len = [len(x) for x in reviews_int]\n",
    "df['Review len'] = review_len\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(review_int: list, seq_len: int) -> np.array:\n",
    "    \"\"\"Make left-sided padding for input list of tokens\n",
    "\n",
    "    Args:\n",
    "        review_int (list): input list of tokens\n",
    "        seq_len (int): max length of sequence, it len(review_int[i]) > seq_len it will be trimmed, else it will be padded by zeros\n",
    "\n",
    "    Returns:\n",
    "        np.array: padded sequences\n",
    "    \"\"\"    \n",
    "    features = np.zeros((len(reviews_int), seq_len), dtype = int)\n",
    "    for i, review in enumerate(review_int):\n",
    "        if len(review) <= seq_len:\n",
    "            zeros = list(np.zeros(seq_len - len(review)))\n",
    "            new = zeros + review\n",
    "        else:\n",
    "            new = review[: seq_len]\n",
    "        features[i, :] = np.array(new)\n",
    "            \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_single_string(input_string: str, seq_len: int, vocab_to_int: dict = vocab_to_int) -> list:\n",
    "    \"\"\"Function for all preprocessing steps on a single string\n",
    "\n",
    "    Args:\n",
    "        input_string (str): input single string for preprocessing\n",
    "        seq_len (int): max length of sequence, it len(review_int[i]) > seq_len it will be trimmed, else it will be padded by zeros\n",
    "        vocab_to_int (dict, optional): word corpus {'word' : int index}. Defaults to vocab_to_int.\n",
    "\n",
    "    Returns:\n",
    "        list: preprocessed string\n",
    "    \"\"\"    \n",
    "\n",
    "    preprocessed_string = data_preprocessing(input_string)\n",
    "    result_list = []\n",
    "    for word in preprocessed_string.split():\n",
    "        try: \n",
    "            result_list.append(vocab_to_int[word])\n",
    "        except KeyError as e:\n",
    "            print(f'{e}: not in dictionary!')\n",
    "    result_padded = padding([result_list], seq_len)[0]\n",
    "\n",
    "    return torch.tensor(result_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3608   199     6   250   332     2   129    30 46982  1147    18     5\n",
      " 17205     1    14   933  2632     1    89  3881     1  1587     2   468\n",
      "  3073    28   334   950  1100     8  6393     1]\n"
     ]
    }
   ],
   "source": [
    "SEQ_LEN = 32\n",
    "features = padding(reviews_int, SEQ_LEN)\n",
    "print(features[3, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(features, df['general'].to_numpy(), test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\n",
    "valid_data = TensorDataset(torch.from_numpy(X_valid), torch.from_numpy(y_valid))\n",
    "\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=BATCH_SIZE, drop_last=True)\n",
    "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=BATCH_SIZE, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(vocab_to_int)+1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(train_loader)\n",
    "sample_x, sample_y = next(dataiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "device='cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ConfigRNN:\n",
    "    vocab_size: int\n",
    "    device: str\n",
    "    n_layers: int\n",
    "    embedding_dim: int\n",
    "    hidden_size: int\n",
    "    seq_len: int\n",
    "    bidirectional: bool or int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Конфигурация модели (пример)\n",
    "class ConfigRNN:\n",
    "    def __init__(self, vocab_size, device, n_layers, embedding_dim, hidden_size, seq_len, bidirectional):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.device = device\n",
    "        self.n_layers = n_layers\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_size = hidden_size\n",
    "        self.seq_len = seq_len\n",
    "        self.bidirectional = bidirectional\n",
    "\n",
    "# Пример словаря и длины последовательности\n",
    "vocab_to_int = {\n",
    "    0: \"Отвратительно! Даже не подходите к этому месту!\",\n",
    "    1: \"Плохо! Лучше бы остался дома.\",\n",
    "    2: \"Удовлетворительно, но не без недостатков. Ешьте на свой страх и риск.\",\n",
    "    3: \"Хорошо! Вполне достойное место для трапезы.\",\n",
    "    4: \"Отлично! Обязательно вернусь еще раз.\",\n",
    "    5: \"Великолепно! Как в раю, только с едой.\",\n",
    "}  # пример словаря\n",
    "SEQ_LEN = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.ConfigRNN at 0x2def15fd0>"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_config = ConfigRNN(\n",
    "    vocab_size=len(vocab_to_int) + 1,\n",
    "    device=\"cpu\",\n",
    "    n_layers=2,\n",
    "    embedding_dim=16,\n",
    "    hidden_size=32,\n",
    "    seq_len=SEQ_LEN,\n",
    "    bidirectional=False,\n",
    ")\n",
    "net_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "RNNNet.__init__() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[278], line 49\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Создание экземпляра модели\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m model_rnn \u001b[38;5;241m=\u001b[39m \u001b[43mRNNNet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m tu\u001b[38;5;241m.\u001b[39mget_model_summary(model_rnn, sample_x\u001b[38;5;241m.\u001b[39mto(net_config\u001b[38;5;241m.\u001b[39mdevice))\n",
      "File \u001b[0;32m~/Desktop/bootcamp/nlp_project-1/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:438\u001b[0m, in \u001b[0;36mModule.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.__init__() got an unexpected keyword argument \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    435\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(kwargs))))\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_super_init \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(args):\n\u001b[0;32m--> 438\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.__init__() takes 1 positional argument but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(args)\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m were\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    439\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m given\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    441\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;124;03mCalls super().__setattr__('a', a) instead of the typical self.a = a\u001b[39;00m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;124;03mto avoid Module.__setattr__ overhead. Module's __setattr__ has special\u001b[39;00m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;124;03mhandling for parameters, submodules, and buffers but simply calls into\u001b[39;00m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;124;03msuper().__setattr__ for all other attributes.\u001b[39;00m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: RNNNet.__init__() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "class RNNNet(nn.Module):\n",
    "    \"\"\"\n",
    "    vocab_size: int, размер словаря (аргумент embedding-слоя)\n",
    "    emb_size:   int, размер вектора для описания каждого элемента последовательности\n",
    "    hidden_dim: int, размер вектора скрытого состояния, default 0\n",
    "    batch_size: int, размер batch\n",
    "    \"\"\"\n",
    "\n",
    "    class RNNNet(nn.Module):\n",
    "        def __init__(self, rnn_conf) -> None:\n",
    "            super().__init__()\n",
    "            self.rnn_conf = rnn_conf\n",
    "            self.seq_len = rnn_conf.seq_len\n",
    "            self.emb_size = rnn_conf.embedding_dim\n",
    "            self.hidden_dim = rnn_conf.hidden_size\n",
    "            self.n_layers = rnn_conf.n_layers\n",
    "            self.vocab_size = rnn_conf.vocab_size\n",
    "            self.bidirectional = rnn_conf.bidirectional\n",
    "\n",
    "            self.embedding = nn.Embedding(self.vocab_size, self.emb_size)\n",
    "            self.rnn_cell = nn.RNN(\n",
    "                input_size=self.emb_size,\n",
    "                hidden_size=self.hidden_dim,\n",
    "                batch_first=True,\n",
    "                bidirectional=self.bidirectional,\n",
    "                num_layers=self.n_layers,\n",
    "            )\n",
    "\n",
    "            self.bidirect_factor = 2 if self.bidirectional else 1\n",
    "            self.linear = nn.Sequential(\n",
    "                nn.Linear(self.hidden_dim * self.seq_len * self.bidirect_factor, 16),\n",
    "                nn.Tanh(),\n",
    "                nn.Linear(16, 5)\n",
    "            )\n",
    "\n",
    "    def model_description(self):\n",
    "        direction = \"bidirect\" if self.bidirectional else \"onedirect\"\n",
    "        return f\"rnn_{direction}_{self.n_layers}\"\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.embedding(x.to(self.rnn_conf.device))\n",
    "        output, _ = self.rnn_cell(x)  # Забираем hidden states со всех промежуточных состояний, второй выход отправляем в _\n",
    "        output = output.contiguous().view(output.size(0), -1)\n",
    "        out = self.linear(output)\n",
    "        return out\n",
    "\n",
    "\n",
    "# Создание экземпляра модели\n",
    "model_rnn = RNNNet(net_config)\n",
    "tu.get_model_summary(model_rnn, sample_x.to(net_config.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Инициализация функции потерь, оптимизатора и метрики\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_rnn = Adam(model_rnn.parameters(), lr=0.001)\n",
    "metric = Accuracy(task='multiclass', num_classes=5).to(net_config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# цикл обучения и валидации 4,30 минуты\n",
    "\n",
    "train_losses_rnn, val_losses_rnn, train_metric_rnn, val_metric_rnn, rnn_time = train_rnn_multiclass(\n",
    "    epochs=5,\n",
    "    model=model_rnn,\n",
    "    train_loader=train_loader,\n",
    "    valid_loader=valid_loader,\n",
    "    optimizer=optimizer_rnn,\n",
    "    rnn_conf=net_config,\n",
    "    criterion=criterion,\n",
    "    metric=metric,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
